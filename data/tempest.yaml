- job:
    name: tempest-compute-host-check
    defaults: global
    node: tempest
    concurrent: true
    scm:
      - git:
          url: ssh://review.rc.nectar.org.au:29418/internal/nectar-testing.git
          credentials-id: cd8b8dd3-b897-4ecb-985d-180d5b6f8498
    builders:
      - shell: |
          #!/bin/bash
          echo
          echo "================================================================="
          echo
          echo "                   CLOUD:   $CLOUD"
          echo "                   AZ:      $AVAILABILITY_ZONE"
          echo "                   HOST:    $HOST"
          echo "                   STARTED: $(date)"
          echo
          echo "================================================================="
          echo
          . /opt/tempest/bin/activate
          tmpdir=`mktemp -d --suffix=_tempest`
          cd $WORKSPACE/tempest
          ./setup_tempest.py --host $HOST -s $AVAILABILITY_ZONE -e $CLOUD -j check-compute-host $tmpdir
          cd $tmpdir
          stestr run --serial --include-list $WORKSPACE/tempest/whitelists/check-compute-host.yaml 2>&1 | grep --line-buffered -vE ' \w+Warning: |self._sock = None'
          RET=${PIPESTATUS[0]}
          rm -rf $tmpdir
          exit $RET
    parameters:
      - choice:
          name: 'CLOUD'
          choices:
            - production
            - testing
            - development
          description: "Cloud to run tempest on (Production, Test, Dev). Leave as Production if unsure."
      - choice:
          name: 'AVAILABILITY_ZONE'
          choices:
            - adelaide
            - ardc-syd-1
            - auckland
            - intersect-01
            - intersect-adelaide
            - melbourne-qh2
            - melbourne-qh2-uom
            - monash-01
            - monash-02
            - pawsey
            - qld
            - swinburne-01
            - tasmania
            - tasmania-02
            - ardctest-artm
            - qh2-test
            - monash-test
            - aucklandtest
            - lani
            - luna
          description: 'Availability zone.'
      - string:
          name: 'HOST'
          description: |
            Nova host to test. <br>
            - Host must be in AVAILABILITY_ZONE; if not nova will return a 'No Valid Host' error.<br>
            - Leave blank to let scheduler choose a host.
    properties:
      - authorization:
          'nobody':
            - job-read
            - job-discover
      - build-discarder:
          num-to-keep: 50
      - build-blocker:
          blocking-jobs:
            - "tempest-cleanup-operator"
          block-level: 'GLOBAL'
    publishers:
      - trigger:
          project: 'tempest-cleanup-operator'
          threshold: 'FAILURE'
- job:
    name: tempest-compute-host-check-advanced
    defaults: global
    node: tempest
    concurrent: true
    scm:
      - git:
          url: ssh://review.rc.nectar.org.au:29418/internal/nectar-testing.git
          credentials-id: cd8b8dd3-b897-4ecb-985d-180d5b6f8498
    builders:
      - shell: |
          #!/bin/bash
          echo
          echo "================================================================="
          echo
          echo "                   CLOUD: $CLOUD"
          echo "                   AZ:    $AVAILABILITY_ZONE"
          echo "                   HOST:  $HOST"
          echo "                   TARGET_HOST: $TARGET_HOST"
          echo "                   BLOCK_MIGRATION: $BLOCK_MIGRATION"
          echo "                   STARTED: $(date)"
          echo
          echo "================================================================="
          echo
          . /opt/tempest/bin/activate
          tmpdir=`mktemp -d --suffix=_tempest`
          cd $WORKSPACE/tempest
          [ $BLOCK_MIGRATION = true ] && enable_block="--block_migration"
          ./setup_tempest.py --host $HOST --target_host $TARGET_HOST $enable_block -s $AVAILABILITY_ZONE -e $CLOUD -j check-compute-host-advanced $tmpdir
          cd $tmpdir
          stestr run --serial --include-list $WORKSPACE/tempest/whitelists/check-compute-host-advanced.yaml 2>&1 | grep --line-buffered -vE ' \w+Warning: |self._sock = None'
          RET=${PIPESTATUS[0]}
          rm -rf $tmpdir
          exit $RET
    parameters:
      - choice:
          name: 'CLOUD'
          choices:
            - production
            - testing
            - development
          description: "Cloud to run tempest on (Production, Test, Dev). Leave as Production if unsure."
      - choice:
          name: 'AVAILABILITY_ZONE'
          choices:
            - adelaide
            - ardc-syd-1
            - auckland
            - intersect-01
            - intersect-adelaide
            - melbourne-qh2
            - melbourne-qh2-uom
            - monash-01
            - monash-02
            - pawsey
            - qld
            - swinburne-01
            - tasmania
            - tasmania-02
            - ardctest-artm
            - qh2-test
            - monash-test
            - aucklandtest
            - lani
            - luna
          description: 'Availability zone.'
      - string:
          name: 'HOST'
          description: |
            Nova host to test. <br>
            - Host must be in AVAILABILITY_ZONE; if not nova will return a 'No Valid Host' error.<br>
            - Leave blank to let scheduler choose a host.
      - string:
          name: 'TARGET_HOST'
          description: |
            Nova target host used by migration tests. <br>
            - Host must be in AVAILABILITY_ZONE; if not nova will return a 'No Valid Host' error.<br>
            - Leave blank to let scheduler choose a host.
      - bool:
          name: 'BLOCK_MIGRATION'
          default: false
          description: "Whether to enable block migration during live migration. (Should enable it when no shared storage)"
    properties:
      - authorization:
          'nobody':
            - job-read
            - job-discover
      - build-discarder:
          num-to-keep: 50
      - build-blocker:
          blocking-jobs:
            - "tempest-cleanup-operator"
          block-level: 'GLOBAL'
    publishers:
      - trigger:
          project: 'tempest-cleanup-operator'
          threshold: 'FAILURE'
- job:
    name: tempest-instance-cold-migration
    defaults: global
    node: tempest
    concurrent: true
    scm:
      - git:
          url: ssh://review.rc.nectar.org.au:29418/internal/nectar-testing.git
          credentials-id: cd8b8dd3-b897-4ecb-985d-180d5b6f8498
    builders:
      - shell: |
          #!/bin/bash
          echo
          echo "================================================================="
          echo
          echo "                   CLOUD: $CLOUD"
          echo "                   AZ:    $AVAILABILITY_ZONE"
          echo "                   HOST:  $HOST"
          echo "                   TARGET_HOST: $TARGET_HOST"
          echo "                   STARTED: $(date)"
          echo
          echo "================================================================="
          echo
          . /opt/tempest/bin/activate
          tmpdir=`mktemp -d --suffix=_tempest`
          cd $WORKSPACE/tempest
          ./setup_tempest.py --host $HOST --target_host $TARGET_HOST -s $AVAILABILITY_ZONE -e $CLOUD -j check-instance-cold-migration $tmpdir
          cd $tmpdir
          stestr run --serial --include-list $WORKSPACE/tempest/whitelists/check-instance-cold-migration.yaml 2>&1 | grep --line-buffered -vE ' \w+Warning: |self._sock = None'
          RET=${PIPESTATUS[0]}
          rm -rf $tmpdir
          exit $RET
    parameters:
      - choice:
          name: 'CLOUD'
          choices:
            - production
            - testing
            - development
          description: "Cloud to run tempest on (Production, Test, Dev). Leave as Production if unsure."
      - choice:
          name: 'AVAILABILITY_ZONE'
          choices:
            - adelaide
            - ardc-syd-1
            - auckland
            - intersect-01
            - intersect-adelaide
            - melbourne-qh2
            - melbourne-qh2-uom
            - monash-01
            - monash-02
            - pawsey
            - qld
            - swinburne-01
            - tasmania
            - tasmania-02
            - ardctest-artm
            - qh2-test
            - monash-test
            - aucklandtest
            - lani
            - luna
          description: 'Availability zone.'
      - string:
          name: 'HOST'
          description: |
            Nova host to test. <br>
            - Host must be in AVAILABILITY_ZONE; if not nova will return a 'No Valid Host' error.<br>
            - Leave blank to let scheduler choose a host.
      - string:
          name: 'TARGET_HOST'
          description: |
            Nova target host used by migration tests. <br>
            - Host must be in AVAILABILITY_ZONE; if not nova will return a 'No Valid Host' error.<br>
            - Leave blank to let scheduler choose a host.
    properties:
      - authorization:
          'nobody':
            - job-read
            - job-discover
      - build-discarder:
          num-to-keep: 50
      - build-blocker:
          blocking-jobs:
            - "tempest-cleanup-operator"
          block-level: 'GLOBAL'
    publishers:
      - trigger:
          project: 'tempest-cleanup-operator'
          threshold: 'FAILURE'
- job:
    name: tempest-instance-live-migration
    defaults: global
    node: tempest
    concurrent: true
    scm:
      - git:
          url: ssh://review.rc.nectar.org.au:29418/internal/nectar-testing.git
          credentials-id: cd8b8dd3-b897-4ecb-985d-180d5b6f8498
    builders:
      - shell: |
          #!/bin/bash
          echo
          echo "================================================================="
          echo
          echo "                   CLOUD: $CLOUD"
          echo "                   AZ:    $AVAILABILITY_ZONE"
          echo "                   HOST:  $HOST"
          echo "                   TARGET_HOST: $TARGET_HOST"
          echo "                   BLOCK_MIGRATION: $BLOCK_MIGRATION"
          echo "                   STARTED: $(date)"
          echo
          echo "================================================================="
          echo
          . /opt/tempest/bin/activate
          tmpdir=`mktemp -d --suffix=_tempest`
          cd $WORKSPACE/tempest
          [ $BLOCK_MIGRATION = true ] && enable_block="--block_migration"
          ./setup_tempest.py --host $HOST --target_host $TARGET_HOST $enable_block -s $AVAILABILITY_ZONE -e $CLOUD -j check-instance-live-migration $tmpdir
          cd $tmpdir
          stestr run --serial --include-list $WORKSPACE/tempest/whitelists/check-instance-live-migration.yaml 2>&1 | grep --line-buffered -vE ' \w+Warning: |self._sock = None'
          RET=${PIPESTATUS[0]}
          rm -rf $tmpdir
          exit $RET
    parameters:
      - choice:
          name: 'CLOUD'
          choices:
            - production
            - testing
            - development
          description: "Cloud to run tempest on (Production, Test, Dev). Leave as Production if unsure."
      - choice:
          name: 'AVAILABILITY_ZONE'
          choices:
            - adelaide
            - ardc-syd-1
            - auckland
            - intersect-01
            - intersect-adelaide
            - melbourne-qh2
            - melbourne-qh2-uom
            - monash-01
            - monash-02
            - pawsey
            - qld
            - swinburne-01
            - tasmania
            - tasmania-02
            - ardctest-artm
            - qh2-test
            - monash-test
            - aucklandtest
            - lani
            - luna
          description: 'Availability zone.'
      - string:
          name: 'HOST'
          description: |
            Nova host to test. <br>
            - Host must be in AVAILABILITY_ZONE; if not nova will return a 'No Valid Host' error.<br>
            - Leave blank to let scheduler choose a host.
      - string:
          name: 'TARGET_HOST'
          description: |
            Nova target host used by migration tests. <br>
            - Host must be in AVAILABILITY_ZONE; if not nova will return a 'No Valid Host' error.<br>
            - Leave blank to let scheduler choose a host.
      - bool:
          name: 'BLOCK_MIGRATION'
          default: false
          description: "Whether to enable block migration during live migration. (Should enable it when no shared storage)"
    properties:
      - authorization:
          'nobody':
            - job-read
            - job-discover
      - build-discarder:
          num-to-keep: 50
      - build-blocker:
          blocking-jobs:
            - "tempest-cleanup-operator"
          block-level: 'GLOBAL'
    publishers:
      - trigger:
          project: 'tempest-cleanup-operator'
          threshold: 'FAILURE'
- job:
    name: tempest-cinder-check
    defaults: global
    node: tempest
    concurrent: true
    scm:
      - git:
          url: ssh://review.rc.nectar.org.au:29418/internal/nectar-testing.git
          credentials-id: cd8b8dd3-b897-4ecb-985d-180d5b6f8498
    builders:
      - shell: |
          #!/bin/bash
          . /opt/tempest/bin/activate
          tmpdir=`mktemp -d --suffix=_tempest`
          cd $WORKSPACE/tempest/
          ./setup_tempest.py -s $AVAILABILITY_ZONE -e $CLOUD -j check-cinder --volume-type $VOLUME_TYPE $tmpdir
          cd $tmpdir
          stestr run --serial --include-list $WORKSPACE/tempest/whitelists/check-cinder.yaml 2>&1 | grep --line-buffered -vE ' \w+Warning: |self._sock = None'
          RET=${PIPESTATUS[0]}
          rm -rf $tmpdir
          exit $RET
    parameters:
      - choice:
          name: 'CLOUD'
          choices:
            - production
            - testing
            - development
          description: "Cloud to run tempest on (Production, Test, Dev). Leave as Production if unsure."
      - choice:
          name: 'AVAILABILITY_ZONE'
          choices:
            - adelaide
            - ardc-syd-1
            - auckland
            - intersect-01
            - intersect-adelaide
            - melbourne-qh2
            - melbourne-qh2-uom
            - monash-01
            - monash-02
            - pawsey
            - qld
            - swinburne-01
            - tasmania
            - tasmania-02
            - ardctest-artm
            - qh2-test
            - monash-test
            - aucklandtest
            - lani
            - luna
          description: 'Availability zone.'
      - choice:
          name: 'VOLUME_TYPE'
          choices:
            - standard
            - encrypted
            - performance
          description: "The volume type to use"
          default: standard
    properties:
      - authorization:
          'nobody':
            - job-read
            - job-discover
      - build-discarder:
          num-to-keep: 50
      - build-blocker:
          blocking-jobs:
            - "tempest-cleanup-operator"
          block-level: 'GLOBAL'
    publishers:
      - trigger:
          project: 'tempest-cleanup-operator'
          threshold: 'FAILURE'
- job:
    name: tempest-magnum-check
    defaults: global
    node: tempest
    concurrent: true
    scm:
      - git:
          url: ssh://review.rc.nectar.org.au:29418/internal/nectar-testing.git
          credentials-id: cd8b8dd3-b897-4ecb-985d-180d5b6f8498
    builders:
      - shell: |
          #!/bin/bash
          . /opt/tempest/bin/activate
          tmpdir=`mktemp -d --suffix=_tempest`
          cd $WORKSPACE/tempest/
          ./setup_tempest.py -s $AVAILABILITY_ZONE -e $CLOUD -j check-magnum $tmpdir
          cd $tmpdir
          stestr run --serial --include-list $WORKSPACE/tempest/whitelists/check-magnum.yaml 2>&1 | grep --line-buffered -vE ' \w+Warning: |self._sock = None'
          RET=${PIPESTATUS[0]}
          rm -rf $tmpdir
          exit $RET
    parameters:
      - choice:
          name: 'CLOUD'
          choices:
            - production
            - testing
            - development
          description: "Cloud to run tempest on (production, testing or development). Leave as Production if unsure."
      - choice:
          name: 'AVAILABILITY_ZONE'
          choices:
            - adelaide
            - ardc-syd-1
            - auckland
            - intersect-01
            - intersect-adelaide
            - melbourne-qh2
            - melbourne-qh2-uom
            - monash-01
            - monash-02
            - pawsey
            - qld
            - swinburne-01
            - tasmania
            - tasmania-02
            - ardctest-artm
            - qh2-test
            - aucklandtest
            - lani
            - luna
          description: 'Availability zone.'
    properties:
      - authorization:
          'nobody':
            - job-read
            - job-discover
      - build-discarder:
          num-to-keep: 50
      - build-blocker:
          blocking-jobs:
            - "tempest-cleanup-operator"
          block-level: 'GLOBAL'
    publishers:
      - trigger:
          project: 'tempest-cleanup-operator'
          threshold: 'FAILURE'
- project:
    name: key-manager
    jobs:
      - 'tempest-{name}-check-site-agnostic':
          whitelist: 'barbican'
- project:
    name: s3
    jobs:
      - 'tempest-{name}-check-site-agnostic':
          whitelist: 's3'
- job:
    name: tempest-neutron-check
    defaults: global
    node: tempest
    concurrent: true
    scm:
      - git:
          url: ssh://review.rc.nectar.org.au:29418/internal/nectar-testing.git
          credentials-id: cd8b8dd3-b897-4ecb-985d-180d5b6f8498
    builders:
      - shell: |
          #!/bin/bash
          . /opt/tempest/bin/activate
          tmpdir=`mktemp -d --suffix=_tempest`
          cd $WORKSPACE/tempest/
          ./setup_tempest.py -e $CLOUD -s $AVAILABILITY_ZONE -j check-scenario $tmpdir
          cd $tmpdir
          stestr run --serial --include-list $WORKSPACE/tempest/whitelists/check-neutron.yaml 2>&1 | grep --line-buffered -vE ' \w+Warning: |self._sock = None'
          RET=${PIPESTATUS[0]}
          rm -rf $tmpdir
          exit $RET
    parameters:
      - choice:
          name: 'CLOUD'
          choices:
            - production
            - testing
            - development
          description: "Cloud to run tempest on (production, testing or development). Leave as Production if unsure."
      - choice:
          name: 'AVAILABILITY_ZONE'
          choices:
            - adelaide
            - ardc-syd-1
            - auckland
            - intersect-01
            - intersect-adelaide
            - melbourne-qh2
            - melbourne-qh2-uom
            - monash-01
            - monash-02
            - pawsey
            - qld
            - swinburne-01
            - tasmania
            - tasmania-02
            - ardctest-artm
            - qh2-test
            - monash-test
            - aucklandtest
            - lani
            - luna
          description: 'Availability zone.'
    properties:
      - authorization:
          'nobody':
            - job-read
            - job-discover
      - build-discarder:
          num-to-keep: 50
      - build-blocker:
          blocking-jobs:
            - "tempest-cleanup-operator"
          block-level: 'GLOBAL'
    publishers:
      - trigger:
          project: 'tempest-cleanup-operator'
          threshold: 'FAILURE'
- project:
    name: neutron-upgrade
    jobs:
      - 'tempest-{name}-check':
          whitelist: 'upgrade-neutron'
- job:
    name: tempest-scenario-check
    defaults: global
    node: tempest
    concurrent: true
    scm:
      - git:
          url: ssh://review.rc.nectar.org.au:29418/internal/nectar-testing.git
          credentials-id: cd8b8dd3-b897-4ecb-985d-180d5b6f8498
    builders:
      - shell: |
          #!/bin/bash
          echo
          echo "================================================================="
          echo
          echo "                   CLOUD:   $CLOUD"
          echo "                   AZ:      $AVAILABILITY_ZONE"
          echo "                   HOST:    $HOST"
          echo "                   STARTED: $(date)"
          echo
          echo "================================================================="
          echo
          . /opt/tempest/bin/activate
          tmpdir=`mktemp -d --suffix=_tempest`
          cd $WORKSPACE/tempest/
          ./setup_tempest.py --host $HOST -s $AVAILABILITY_ZONE -e $CLOUD -j check-scenario $tmpdir
          cd $tmpdir
          stestr run --serial --include-list $WORKSPACE/tempest/whitelists/check-scenario.yaml 2>&1 | grep --line-buffered -vE ' \w+Warning: |self._sock = None'
          RET=${PIPESTATUS[0]}
          rm -rf $tmpdir
          exit $RET
    parameters:
      - choice:
          name: 'CLOUD'
          choices:
            - production
            - testing
            - development
          description: "Cloud to run tempest on (Production, Test, Dev). Leave as Production if unsure."
      - choice:
          name: 'AVAILABILITY_ZONE'
          choices:
            - adelaide
            - ardc-syd-1
            - auckland
            - intersect-01
            - intersect-adelaide
            - melbourne-qh2
            - melbourne-qh2-uom
            - monash-01
            - monash-02
            - pawsey
            - qld
            - swinburne-01
            - tasmania
            - tasmania-02
            - ardctest-artm
            - qh2-test
            - monash-test
            - aucklandtest
            - lani
            - luna
          description: 'Availability zone.'
      - string:
          name: 'HOST'
          description: |
            Nova host to test. <br>
            - Host must be in AVAILABILITY_ZONE; if not nova will return a 'No Valid Host' error.<br>
            - Leave blank to let scheduler choose a host.
    properties:
      - authorization:
          'nobody':
            - job-read
            - job-discover
      - build-discarder:
          num-to-keep: 50
      - build-blocker:
          blocking-jobs:
            - "tempest-cleanup-operator"
          block-level: 'GLOBAL'
    publishers:
      - trigger:
          project: 'tempest-cleanup-operator'
          threshold: 'FAILURE'
- job:
    name: tempest-murano-check
    defaults: global
    node: tempest
    concurrent: true
    scm:
      - git:
          url: ssh://review.rc.nectar.org.au:29418/internal/nectar-testing.git
          credentials-id: cd8b8dd3-b897-4ecb-985d-180d5b6f8498
    builders:
      - shell: |
          #!/bin/bash
          . /opt/tempest/bin/activate
          tmpdir=`mktemp -d --suffix=_tempest`
          cd $WORKSPACE/tempest/
          ./setup_tempest.py -s $AVAILABILITY_ZONE -e $CLOUD -j check-murano $tmpdir
          cd $tmpdir
          stestr run -n murano_tempest_tests.tests.scenario.application_catalog.test_deployment.TestMuranoDeployment.test_app_deployment 2>&1 | grep --line-buffered -vE ' \w+Warning: |self._sock = None'
          RET=${PIPESTATUS[0]}
          rm -rf $tmpdir
          exit $RET
    parameters:
      - choice:
          name: 'CLOUD'
          choices:
            - production
            - testing
            - development
          description: "Cloud to run tempest on (Production, Test, Dev). Leave as Production if unsure."
      - choice:
          name: 'AVAILABILITY_ZONE'
          choices:
            - adelaide
            - ardc-syd-1
            - auckland
            - intersect-01
            - intersect-adelaide
            - melbourne-qh2
            - melbourne-qh2-uom
            - monash-01
            - monash-02
            - pawsey
            - qld
            - swinburne-01
            - tasmania
            - tasmania-02
            - ardctest-artm
            - qh2-test
            - monash-test
            - aucklandtest
            - lani
            - luna
          description: 'Availability zone.'
    properties:
      - authorization:
          'nobody':
            - job-read
            - job-discover
      - build-discarder:
          num-to-keep: 50
      - build-blocker:
          blocking-jobs:
            - "tempest-cleanup-operator"
          block-level: 'GLOBAL'
    publishers:
      - trigger:
          project: 'tempest-cleanup-operator'
          threshold: 'FAILURE'
- job:
    name: tempest-trove-check
    defaults: global
    node: tempest
    concurrent: true
    scm:
      - git:
          url: ssh://review.rc.nectar.org.au:29418/internal/nectar-testing.git
          credentials-id: cd8b8dd3-b897-4ecb-985d-180d5b6f8498
    builders:
      - shell: |
          #!/bin/bash
          . /opt/tempest/bin/activate
          tmpdir=`mktemp -d --suffix=_tempest`
          cd $WORKSPACE/tempest/
          ./setup_tempest.py -s $AVAILABILITY_ZONE -e $CLOUD -j check-trove $tmpdir
          cd $tmpdir
          stestr run -n trove_tempest_plugin.tests.scenario.database.test_basic_instance_ops.DatabaseScenarioTest.test_create_instances 2>&1 | grep --line-buffered -vE ' \w+Warning: |self._sock = None'
          RET=${PIPESTATUS[0]}
          rm -rf $tmpdir
          exit $RET
    parameters:
      - choice:
          name: 'CLOUD'
          choices:
            - production
            - testing
            - development
          description: "Cloud to run tempest on (Production, Test, Dev). Leave as Production if unsure."
      - choice:
          name: 'AVAILABILITY_ZONE'
          choices:
            - adelaide
            - ardc-syd-1
            - auckland
            - intersect-01
            - intersect-adelaide
            - melbourne-qh2
            - melbourne-qh2-uom
            - monash-01
            - monash-02
            - pawsey
            - qld
            - swinburne-01
            - tasmania
            - tasmania-02
            - ardctest-artm
            - qh2-test
            - monash-test
            - aucklandtest
            - lani
            - luna
          description: 'Availability zone.'
    properties:
      - authorization:
          'nobody':
            - job-read
            - job-discover
      - build-discarder:
          num-to-keep: 50
      - build-blocker:
          blocking-jobs:
            - "tempest-cleanup-operator"
          block-level: 'GLOBAL'
    publishers:
      - trigger:
          project: 'tempest-cleanup-operator'
          threshold: 'FAILURE'
- job:
    name: tempest-blazar-check
    defaults: global
    node: tempest
    concurrent: true
    scm:
      - git:
          url: ssh://review.rc.nectar.org.au:29418/internal/nectar-testing.git
          credentials-id: cd8b8dd3-b897-4ecb-985d-180d5b6f8498
    builders:
      - shell: |
          #!/bin/bash
          . /opt/tempest/bin/activate
          tmpdir=`mktemp -d --suffix=_tempest`
          cd $WORKSPACE/tempest
          ./setup_tempest.py -s $AVAILABILITY_ZONE -e $CLOUD --blazar-resource-properties "$BLAZAR_RESOURCE_PROPERTIES" --blazar-extra-specs "$BLAZAR_EXTRA_SPECS" -j check-blazar $tmpdir
          cd $tmpdir
          stestr run --serial --include-list $WORKSPACE/tempest/whitelists/check-blazar.yaml 2>&1 | grep --line-buffered -vE ' \w+Warning: |self._sock = None'
          RET=${PIPESTATUS[0]}
          rm -rf $tmpdir
          exit $RET
    parameters:
      - choice:
          name: 'CLOUD'
          choices:
            - production
            - testing
            - development
          description: "Cloud to run tempest on (Production, Test, Dev). Leave as Production if unsure."
      - choice:
          name: 'AVAILABILITY_ZONE'
          choices:
            - adelaide
            - ardc-syd-1
            - auckland
            - intersect-01
            - intersect-adelaide
            - melbourne-qh2
            - melbourne-qh2-uom
            - monash-01
            - monash-02
            - pawsey
            - qld
            - swinburne-01
            - tasmania
            - tasmania-02
            - ardctest-artm
            - qh2-test
            - monash-test
            - aucklandtest
            - lani
            - luna
          description: 'Availability zone.'
      - string:
          name: 'BLAZAR_RESOURCE_PROPERTIES'
          description: |
            Optional. Specify Blazar resource_properties. <br>
            - e.g. To test creating a lease on a host in Auckland zone with a custom capability, specify <br>
            - '["and", ["=", "\$$availability_zone", "auckland"], ["=", "\$$custom_key", "custom_value"]]'
      - string:
          name: 'BLAZAR_EXTRA_SPECS'
          description: |
            Optional. Specify Blazar extra_specs. <br>
            - e.g. To test creating a lease for a P40 GPU, specify <br>
            - '{"pci_passthrough:alias":"P40:1"}'
    properties:
      - authorization:
          'nobody':
            - job-read
            - job-discover
      - build-discarder:
          num-to-keep: 50
      - build-blocker:
          blocking-jobs:
            - "tempest-cleanup-operator"
          block-level: 'GLOBAL'
    publishers:
      - trigger:
          project: 'tempest-cleanup-operator'
          threshold: 'FAILURE'
- project:
    name: trove-mysql
    jobs:
      - 'tempest-{name}-check':
          whitelist: 'trove'
- project:
    name: trove-postgresql
    jobs:
      - 'tempest-{name}-check':
          whitelist: 'trove'
- project:
    name: trove-mysql-8.0
    jobs:
      - 'tempest-{name}-check':
          whitelist: 'trove'
- project:
    name: heat-scenario
    jobs:
      - 'tempest-{name}-check':
          whitelist: 'heat'
- project:
    name: octavia-smoke
    jobs:
      - 'tempest-{name}-check':
          whitelist: 'octavia'
- project:
    name: octavia-smoke-rctest
    jobs:
      - 'tempest-{name}-check-{site}':
          job: 'octavia-smoke'
          whitelist: 'octavia'
          cloud: 'testing'
          site:
            - ardctest-artm
- project:
    name: s3-rctest
    jobs:
      - 'tempest-{name}-check-site-agnostic-{cloud}':
          job: 's3'
          whitelist: 's3'
          cloud: 'testing'
- project:
    name: heat-scenario-rctest
    jobs:
      - 'tempest-{name}-check-{site}':
          job: 'heat-scenario'
          whitelist: 'heat'
          cloud: 'testing'
          site:
            - ardctest-artm
            - qh2-test
            - monash-test
            - aucklandtest
- project:
    name: manila-scenario
    jobs:
      - 'tempest-{name}-check':
          whitelist: 'manila'
- project:
    name: manila-nfs
    jobs:
      - 'tempest-{name}-check':
          whitelist: 'manila-nfs'
- project:
    name: manila-cephfs
    jobs:
      - 'tempest-{name}-check':
          whitelist: 'manila-cephfs'
- project:
    name: tempest-nagios-services-manila-nfs
    site:
      - auckland
    jobs:
      - 'tempest-nagios-services-{site}-{test}':
          test:
            - 'share_nfs'
          skip_capacity_check: true
          environment: 'production'
- project:
    name: tempest-nagios-services-manila-cephfs
    site:
      - monash-02
    jobs:
      - 'tempest-nagios-services-{site}-{test}':
          test:
            - 'share_cephfs'
          skip_capacity_check: true
          environment: 'production'
- project:
    name: tempest-nagios-services
    site:
      - adelaide
      - ardc-syd-1
      - auckland
      - intersect-01
      - intersect-adelaide
      - melbourne-qh2
      - melbourne-qh2-uom
      - monash-01
      - monash-02
      - pawsey
      - qld
      - swinburne-01
      - tasmania
      - tasmania-02
    jobs:
      - 'tempest-nagios-services-{site}-{test}':
          test:
            - 'orchestration'
            - 'database'
            - 'application'
          skip_capacity_check: false
          environment: 'production'
- project:
    name: tempest-nagios-services-volume-backup
    site:
      - adelaide
      - ardc-syd-1
      - auckland
      - melbourne-qh2
      - melbourne-qh2-uom
      - monash-01
      - monash-02
      - pawsey
      - qld
      - swinburne-01
      - tasmania
      - tasmania-02
    jobs:
      - 'tempest-nagios-services-{site}-{test}':
          test:
            - 'volume_backup'
          skip_capacity_check: false
          environment: 'production'
- project:
    name: tempest-nagios-services-advanced-network
    site:
      - adelaide
      - ardc-syd-1
      - auckland
      - intersect-01
      - intersect-adelaide
      - melbourne-qh2
      - melbourne-qh2-uom
      - monash-01
      - monash-02
      - pawsey
      - qld
      - swinburne-01
      - tasmania
    jobs:
      - 'tempest-nagios-services-{site}-{test}':
          test:
            - 'coe'
            - 'loadbalancer'
          skip_capacity_check: false
          environment: 'production'
- project:
    name: tempest-nagios-services-rctest
    site:
      - ardctest-artm
      - qh2-test
      - monash-test
      - aucklandtest
    jobs:
      - 'tempest-nagios-services-{site}-{test}':
          test:
            - 'volume'
            - 'volume_backup'
            - 'orchestration'
            - 'loadbalancer'
            - 'database'
            - 'coe'
            - 'application'
          skip_capacity_check: false
          environment: 'testing'
- project:
    name: tempest-nagios-services-site-agnostic
    environment: 'production'
    jobs:
      - 'tempest-nagios-services-{test}-{environment}':
          test:
            - 'image'
            - 'object'
            - 'dns'
          skip_capacity_check: true
- project:
    name: tempest-nagios-services-site-agnostic-rctest
    environment: 'testing'
    jobs:
      - 'tempest-nagios-services-{test}-{environment}':
          test:
            - 'image'
            - 'object'
            - 'dns'
          skip_capacity_check: true
- project:
    name: telemetry
    jobs:
      - 'tempest-{name}-check':
          whitelist: 'telemetry'
- project:
    name: telemetry-rctest
    cloud: 'testing'
    jobs:
      - 'tempest-{name}-check-{site}':
          job: 'telemetry'
          whitelist: 'telemetry'
          site:
            - ardctest-artm
      - 'tempest-cleanup-telemetry-{cloud}'
- project:
    name: glance-scenario
    jobs:
      - 'tempest-{name}-check-site-agnostic':
          whitelist: 'glance'
- project:
    name: glance-scenario-rctest
    jobs:
      - 'tempest-{name}-check-site-agnostic-{cloud}':
          job: 'glance-scenario'
          whitelist: 'glance'
          cloud: 'testing'
- project:
    name: swift-scenario
    jobs:
      - 'tempest-{name}-check-site-agnostic':
          whitelist: 'swift'
- project:
    name: swift-scenario-rctest
    jobs:
      - 'tempest-{name}-check-site-agnostic-{cloud}':
          job: 'swift-scenario'
          whitelist: 'swift'
          cloud: 'testing'
- job:
    name: tempest-designate-check
    defaults: global
    node: tempest
    concurrent: true
    scm:
      - git:
          url: ssh://review.rc.nectar.org.au:29418/internal/nectar-testing.git
          credentials-id: cd8b8dd3-b897-4ecb-985d-180d5b6f8498
    builders:
      - shell: |
          #!/bin/bash
          . /opt/tempest/bin/activate
          tmpdir=`mktemp -d --suffix=_tempest`
          cd $WORKSPACE/tempest/
          ./setup_tempest.py -e $CLOUD -j check-designate $tmpdir
          cd $tmpdir
          stestr run -n designate_tempest_plugin.tests.scenario.v2.test_recordsets.RecordsetsTest 2>&1 | grep --line-buffered -vE ' \w+Warning: |self._sock = None'
          RET=${PIPESTATUS[0]}
          rm -rf $tmpdir
          exit $RET
    parameters:
      - choice:
          name: 'CLOUD'
          choices:
            - production
            - testing
            - development
          description: "Cloud to run tempest on (Production, Test, Dev). Leave as Production if unsure."
    properties:
      - authorization:
          'nobody':
            - job-read
            - job-discover
      - build-discarder:
          num-to-keep: 20
      - build-blocker:
          blocking-jobs:
            - "tempest-cleanup-operator"
          block-level: 'GLOBAL'
    publishers:
      - trigger:
          project: 'tempest-cleanup-operator'
          threshold: 'FAILURE'
- job:
    name: tempest-rctest-compute-host-check
    defaults: global
    node: tempest
    concurrent: true
    scm:
      - git:
          url: ssh://review.rc.nectar.org.au:29418/internal/nectar-testing.git
          credentials-id: cd8b8dd3-b897-4ecb-985d-180d5b6f8498
    builders:
      - shell: |
          #!/bin/bash
          echo
          echo "================================================================="
          echo
          echo "                   CLOUD:   testing"
          echo "                   AZ:      ardctest-artm"
          echo "                   STARTED: $(date)"
          echo
          echo "================================================================="
          echo
          . /opt/tempest/bin/activate
          tmpdir=`mktemp -d --suffix=_tempest`
          cd $WORKSPACE/tempest
          ./setup_tempest.py -s ardctest-artm -e testing -j check-compute-host $tmpdir
          cd $tmpdir
          stestr run --serial --include-list $WORKSPACE/tempest/whitelists/check-compute-host.yaml 2>&1 | grep --line-buffered -vE ' \w+Warning: |self._sock = None'
          RET=${PIPESTATUS[0]}
          rm -rf $tmpdir
          exit $RET
    properties:
      - authorization:
          'nobody':
            - job-read
            - job-discover
      - build-discarder:
          num-to-keep: 20
      - throttle:
          categories:
            - tempest-rctest
          option: category
- job:
    name: tempest-rctest-compute-host-check-advanced
    defaults: global
    node: tempest
    concurrent: true
    scm:
      - git:
          url: ssh://review.rc.nectar.org.au:29418/internal/nectar-testing.git
          credentials-id: cd8b8dd3-b897-4ecb-985d-180d5b6f8498
    builders:
      - shell: |
          #!/bin/bash
          echo
          echo "================================================================="
          echo
          echo "                   CLOUD:   testing"
          echo "                   AZ:      ardctest-artm"
          echo "                   STARTED: $(date)"
          echo
          echo "================================================================="
          echo
          . /opt/tempest/bin/activate
          tmpdir=`mktemp -d --suffix=_tempest`
          cd $WORKSPACE/tempest
          ./setup_tempest.py --host cc1.svc.artm.ardctest.nectar.org.au --target_host cc2.svc.artm.ardctest.nectar.org.au -s ardctest-artm -e testing -j check-compute-host-advanced --block_migration $tmpdir
          cd $tmpdir
          stestr run --serial --include-list $WORKSPACE/tempest/whitelists/check-compute-host-advanced.yaml 2>&1 | grep --line-buffered -vE ' \w+Warning: |self._sock = None'
          RET=${PIPESTATUS[0]}
          rm -rf $tmpdir
          exit $RET
    properties:
      - authorization:
          'nobody':
            - job-read
            - job-discover
      - build-discarder:
          num-to-keep: 20
- job:
    name: tempest-rctest-cinder-check
    defaults: global
    node: tempest
    concurrent: true
    scm:
      - git:
          url: ssh://review.rc.nectar.org.au:29418/internal/nectar-testing.git
          credentials-id: cd8b8dd3-b897-4ecb-985d-180d5b6f8498
    builders:
      - shell: |
          #!/bin/bash
          . /opt/tempest/bin/activate
          tmpdir=`mktemp -d --suffix=_tempest`
          cd $WORKSPACE/tempest/
          ./setup_tempest.py -s ardctest-artm -e testing -j check-cinder $tmpdir
          cd $tmpdir
          stestr run --serial --include-list $WORKSPACE/tempest/whitelists/check-cinder.yaml 2>&1 | grep --line-buffered -vE ' \w+Warning: |self._sock = None'
          RET=${PIPESTATUS[0]}
          rm -rf $tmpdir
          exit $RET
    properties:
      - authorization:
          'nobody':
            - job-read
            - job-discover
      - build-discarder:
          num-to-keep: 20
      - throttle:
          categories:
            - tempest-rctest
          option: category
- job:
    name: tempest-rctest-magnum-check
    defaults: global
    node: tempest
    concurrent: true
    scm:
      - git:
          url: ssh://review.rc.nectar.org.au:29418/internal/nectar-testing.git
          credentials-id: cd8b8dd3-b897-4ecb-985d-180d5b6f8498
    builders:
      - shell: |
          #!/bin/bash
          . /opt/tempest/bin/activate
          tmpdir=`mktemp -d --suffix=_tempest`
          cd $WORKSPACE/tempest/
          ./setup_tempest.py -s ardctest-artm -e testing -j check-magnum $tmpdir
          cd $tmpdir
          stestr run --serial --include-list $WORKSPACE/tempest/whitelists/check-magnum.yaml 2>&1 | grep --line-buffered -vE ' \w+Warning: |self._sock = None'
          RET=${PIPESTATUS[0]}
          rm -rf $tmpdir
          exit $RET
    properties:
      - authorization:
          'nobody':
            - job-read
            - job-discover
      - build-discarder:
          num-to-keep: 20
      - throttle:
          categories:
            - tempest-rctest
          option: category
- job:
    name: tempest-rctest-neutron-check
    defaults: global
    node: tempest
    concurrent: true
    scm:
      - git:
          url: ssh://review.rc.nectar.org.au:29418/internal/nectar-testing.git
          credentials-id: cd8b8dd3-b897-4ecb-985d-180d5b6f8498
    builders:
      - shell: |
          #!/bin/bash
          . /opt/tempest/bin/activate
          tmpdir=`mktemp -d --suffix=_tempest`
          cd $WORKSPACE/tempest/
          ./setup_tempest.py -s ardctest-artm -e testing -j check-scenario $tmpdir
          cd $tmpdir
          stestr run --serial --include-list $WORKSPACE/tempest/whitelists/check-neutron.yaml 2>&1 | grep --line-buffered -vE ' \w+Warning: |self._sock = None'
          RET=${PIPESTATUS[0]}
          rm -rf $tmpdir
          exit $RET
    properties:
      - authorization:
          'nobody':
            - job-read
            - job-discover
      - build-discarder:
          num-to-keep: 20
      - throttle:
          categories:
            - tempest-rctest
          option: category
- job:
    name: tempest-rctest-scenario-check
    defaults: global
    node: tempest
    concurrent: true
    scm:
      - git:
          url: ssh://review.rc.nectar.org.au:29418/internal/nectar-testing.git
          credentials-id: cd8b8dd3-b897-4ecb-985d-180d5b6f8498
    builders:
      - shell: |
          #!/bin/bash
          . /opt/tempest/bin/activate
          tmpdir=`mktemp -d --suffix=_tempest`
          cd $WORKSPACE/tempest/
          ./setup_tempest.py -s ardctest-artm -e testing -j check-scenario $tmpdir
          cd $tmpdir
          stestr run --serial --include-list $WORKSPACE/tempest/whitelists/check-scenario.yaml 2>&1 | grep --line-buffered -vE ' \w+Warning: |self._sock = None'
          RET=${PIPESTATUS[0]}
          rm -rf $tmpdir
          exit $RET
    properties:
      - authorization:
          'nobody':
            - job-read
            - job-discover
      - build-discarder:
          num-to-keep: 20
      - throttle:
          categories:
            - tempest-rctest
          option: category
- job:
    name: tempest-rctest-murano-check
    defaults: global
    node: tempest
    concurrent: true
    scm:
      - git:
          url: ssh://review.rc.nectar.org.au:29418/internal/nectar-testing.git
          credentials-id: cd8b8dd3-b897-4ecb-985d-180d5b6f8498
    builders:
      - shell: |
          #!/bin/bash
          . /opt/tempest/bin/activate
          tmpdir=`mktemp -d --suffix=_tempest`
          cd $WORKSPACE/tempest/
          ./setup_tempest.py -s ardctest-artm -e testing -j check-murano $tmpdir
          cd $tmpdir
          stestr run -n murano_tempest_tests.tests.scenario.application_catalog.test_deployment.TestMuranoDeployment.test_app_deployment 2>&1 | grep --line-buffered -vE ' \w+Warning: |self._sock = None'
          RET=${PIPESTATUS[0]}
          rm -rf $tmpdir
          exit $RET
    properties:
      - authorization:
          'nobody':
            - job-read
            - job-discover
      - build-discarder:
          num-to-keep: 20
      - throttle:
          categories:
            - tempest-rctest
          option: category
- job:
    name: tempest-rctest-trove-check
    defaults: global
    node: tempest
    concurrent: true
    scm:
      - git:
          url: ssh://review.rc.nectar.org.au:29418/internal/nectar-testing.git
          credentials-id: cd8b8dd3-b897-4ecb-985d-180d5b6f8498
    builders:
      - shell: |
          #!/bin/bash
          . /opt/tempest/bin/activate
          tmpdir=`mktemp -d --suffix=_tempest`
          cd $WORKSPACE/tempest/
          ./setup_tempest.py -s ardctest-artm -e testing -j check-trove $tmpdir
          cd $tmpdir
          stestr run -n trove_tempest_plugin.tests.scenario.database.test_basic_instance_ops.DatabaseScenarioTest.test_create_instances 2>&1 | grep --line-buffered -vE ' \w+Warning: |self._sock = None'
          RET=${PIPESTATUS[0]}
          rm -rf $tmpdir
          exit $RET
    properties:
      - authorization:
          'nobody':
            - job-read
            - job-discover
      - build-discarder:
          num-to-keep: 20
      - throttle:
          categories:
            - tempest-rctest
          option: category
- job:
    name: tempest-rctest-designate-check
    defaults: global
    node: tempest
    concurrent: true
    scm:
      - git:
          url: ssh://review.rc.nectar.org.au:29418/internal/nectar-testing.git
          credentials-id: cd8b8dd3-b897-4ecb-985d-180d5b6f8498
    builders:
      - shell: |
          #!/bin/bash
          . /opt/tempest/bin/activate
          tmpdir=`mktemp -d --suffix=_tempest`
          cd $WORKSPACE/tempest/
          ./setup_tempest.py -e testing -j check-designate $tmpdir
          cd $tmpdir
          stestr run -n designate_tempest_plugin.tests.scenario.v2.test_recordsets.RecordsetsTest 2>&1 | grep --line-buffered -vE ' \w+Warning: |self._sock = None'
          RET=${PIPESTATUS[0]}
          rm -rf $tmpdir
          exit $RET
    properties:
      - authorization:
          'nobody':
            - job-read
            - job-discover
      - build-discarder:
          num-to-keep: 20
      - throttle:
          categories:
            - tempest-rctest
          option: category
- project:
    name: tempest-nagios-site-compute
    site:
      - adelaide
      - ardc-syd-1
      - auckland
      - intersect-01
      - intersect-adelaide
      - melbourne-qh2
      - melbourne-qh2-uom
      - monash-01
      - monash-02
      - pawsey
      - qld
      - swinburne-01
      - tasmania
      - tasmania-02
    jobs:
      - 'tempest-nagios-site-{site}-{test}':
          test:
            - 'compute'
      - 'tempest-cleanup-site-{site}'
- project:
    name: tempest-nagios-site-network
    site:
      - adelaide
      - ardc-syd-1
      - auckland
      - intersect-01
      - intersect-adelaide
      - melbourne-qh2
      - melbourne-qh2-uom
      - monash-01
      - monash-02
      - pawsey
      - qld
      - swinburne-01
      - tasmania
    jobs:
      - 'tempest-nagios-site-{site}-{test}':
          test:
            - 'network'
- project:
    name: tempest-nagios-site-volume
    site:
      - adelaide
      - ardc-syd-1
      - auckland
      - intersect-01
      - intersect-adelaide
      - melbourne-qh2
      - melbourne-qh2-uom
      - monash-01
      - monash-02
      - pawsey
      - qld
      - swinburne-01
      - tasmania
      - tasmania-02
    jobs:
      - 'tempest-nagios-site-{site}-{test}':
          test:
            - 'volume'
- project:
    name: tempest-nagios-flavor
    flavor:
      - xsmall
      - small
      - medium
      - large
      - xlarge
      - xxlarge
    jobs:
      - 'tempest-nagios-flavor-{flavor}-{test}':
          test:
            - 'compute'
- job-template:
    name: 'tempest-nagios-site-{site}-{test}'
    defaults: global
    node: tempest
    concurrent: false
    scm:
      - git:
          url: ssh://review.rc.nectar.org.au:29418/internal/nectar-testing.git
          credentials-id: cd8b8dd3-b897-4ecb-985d-180d5b6f8498
    wrappers:
      - timeout:
          timeout: 10
          fail: true
    builders:
      - shell: |
          . /opt/tempest/bin/activate
          $WORKSPACE/nagios/tempest_nagios.py tempest -c $WORKSPACE/nagios/tempest_nagios.conf -s {site} -t {test} -e production
    triggers:
      - timed: 'H(1-59)/30 * * * *'
    publishers:
      - naginator:
          max-failed-builds: 2
          fixed-delay: 30
      - trigger:
          project: 'tempest-cleanup-site-{site}'
          threshold: 'FAILURE'
    properties:
      - authorization:
          'anonymous':
            - job-read
            - job-discover
      - build-discarder:
          days-to-keep: 45
      - build-blocker:
          blocking-jobs:
            - "^tempest-cleanup-site-{site}.*"
          block-level: 'GLOBAL'
- job-template:
    name: 'tempest-nagios-flavor-{flavor}-{test}'
    defaults: global
    node: tempest
    concurrent: false
    scm:
      - git:
          url: ssh://review.rc.nectar.org.au:29418/internal/nectar-testing.git
          credentials-id: cd8b8dd3-b897-4ecb-985d-180d5b6f8498
    wrappers:
      - timeout:
          timeout: 45
          fail: true
    builders:
      - shell: |
          . /opt/tempest/bin/activate
          $WORKSPACE/nagios/tempest_nagios.py tempest -c $WORKSPACE/nagios/tempest_nagios.conf -f {flavor} -t {test} -e production
    triggers:
      - timed: 'H(1-59) * * * *'
    publishers:
      - naginator:
          max-failed-builds: 2
          fixed-delay: 30
      - trigger:
          project: 'tempest-cleanup'
          threshold: 'FAILURE'
    properties:
      - authorization:
          'anonymous':
            - job-read
            - job-discover
      - build-discarder:
          days-to-keep: 7
- job-template:
    name: 'tempest-nagios-services-{site}-{test}'
    defaults: global
    node: tempest
    concurrent: false
    scm:
      - git:
          url: ssh://review.rc.nectar.org.au:29418/internal/nectar-testing.git
          credentials-id: cd8b8dd3-b897-4ecb-985d-180d5b6f8498
    wrappers:
      - timeout:
          timeout: 45
          fail: true
    builders:
      - shell: |
          . /opt/tempest/bin/activate
          [ {skip_capacity_check} == True ] && skip_capacity_check="--skip-capacity-check"
          $WORKSPACE/nagios/tempest_nagios.py tempest -c $WORKSPACE/nagios/tempest_nagios.conf -s {site} -t {test} -e {environment} $skip_capacity_check
    triggers:
      - timed: 'H(1-59) H(4-6) * * *'
    publishers:
      - naginator:
          max-failed-builds: 1
          fixed-delay: 30
      - trigger:
          project: 'tempest-cleanup-site-{site}'
          threshold: 'FAILURE'
    properties:
      - authorization:
          'anonymous':
            - job-read
            - job-discover
      - build-discarder:
          days-to-keep: 7
      - build-blocker:
          blocking-jobs:
            - "^tempest-nagios-site-{site}.*"
            - "^tempest-nagios-services-{site}.*"
            - "^tempest-cleanup-site-{site}.*"
          block-level: 'GLOBAL'
- job-template:
    name: 'tempest-nagios-services-{test}-{environment}'
    defaults: global
    node: tempest
    concurrent: false
    scm:
      - git:
          url: ssh://review.rc.nectar.org.au:29418/internal/nectar-testing.git
          credentials-id: cd8b8dd3-b897-4ecb-985d-180d5b6f8498
    wrappers:
      - timeout:
          timeout: 45
          fail: true
    builders:
      - shell: |
          . /opt/tempest/bin/activate
          [ {skip_capacity_check} == True ] && skip_capacity_check="--skip-capacity-check"
          $WORKSPACE/nagios/tempest_nagios.py tempest -c $WORKSPACE/nagios/tempest_nagios.conf -t {test} -e {environment} $skip_capacity_check
    triggers:
      - timed: 'H(1-59) H(3-4) * * *'
    publishers:
      - naginator:
          max-failed-builds: 1
          fixed-delay: 30
      - trigger:
          project: 'tempest-cleanup'
          threshold: 'FAILURE'
    properties:
      - authorization:
          'anonymous':
            - job-read
            - job-discover
      - build-discarder:
          days-to-keep: 7
- job-template:
    name: 'tempest-cleanup-site-{site}'
    defaults: global
    node: tempest
    concurrent: false
    scm:
      - git:
          url: ssh://review.rc.nectar.org.au:29418/internal/nectar-testing.git
          credentials-id: cd8b8dd3-b897-4ecb-985d-180d5b6f8498
    wrappers:
      - timeout:
          timeout: 5
          fail: true
    builders:
      - shell: |
          . /opt/tempest/bin/activate
          $WORKSPACE/nagios/tempest_purge.py -e production -s {site} --no-dry-run
    properties:
      - authorization:
          'anonymous':
            - job-read
            - job-discover
      - build-blocker:
          blocking-jobs:
            - "^tempest-nagios-site-{site}-.*"
            - "^tempest-nagios-services-{site}.*"
          block-level: 'GLOBAL'
      - build-discarder:
          days-to-keep: 7
- job-template:
    name: 'tempest-cleanup-telemetry-{cloud}'
    defaults: global
    node: tempest
    concurrent: false
    scm:
      - git:
          url: ssh://review.rc.nectar.org.au:29418/internal/nectar-testing.git
          credentials-id: cd8b8dd3-b897-4ecb-985d-180d5b6f8498
    wrappers:
      - timeout:
          timeout: 5
          fail: true
    triggers:
      - timed: '30 3 * * *'
    builders:
      - shell: |
          . /opt/tempest/bin/activate
          $WORKSPACE/nagios/tempest_purge.py -e {cloud} -j check-telemetry --no-dry-run
    properties:
      - authorization:
          'anonymous':
            - job-read
            - job-discover
      - build-blocker:
          blocking-jobs:
            - "^tempest-telemetry-.*"
          block-level: 'GLOBAL'
      - build-discarder:
          days-to-keep: 7
- job:
    name: 'tempest-cleanup'
    defaults: global
    node: tempest
    concurrent: false
    scm:
      - git:
          url: ssh://review.rc.nectar.org.au:29418/internal/nectar-testing.git
          credentials-id: cd8b8dd3-b897-4ecb-985d-180d5b6f8498
    wrappers:
      - timeout:
          timeout: 5
          fail: true
    builders:
      - shell: |
          . /opt/tempest/bin/activate
          $WORKSPACE/nagios/tempest_purge.py -e production --no-dry-run
    properties:
      - authorization:
          'anonymous':
            - job-read
            - job-discover
      - build-blocker:
          blocking-jobs:
            - "^tempest-nagios-flavor-.*"
          block-level: 'GLOBAL'
          queue-scanning: 'ALL'
      - build-discarder:
          days-to-keep: 7
- job:
    name: 'tempest-cleanup-operator'
    defaults: global
    node: tempest
    concurrent: false
    scm:
      - git:
          url: ssh://review.rc.nectar.org.au:29418/internal/nectar-testing.git
          credentials-id: cd8b8dd3-b897-4ecb-985d-180d5b6f8498
    wrappers:
      - timeout:
          timeout: 5
          fail: true
    builders:
      - shell: |
          . /opt/tempest/bin/activate
          $WORKSPACE/nagios/tempest_purge.py -e production -j operator --no-dry-run
          $WORKSPACE/nagios/tempest_purge.py -e production -j operator -s auckland --no-dry-run
    triggers:
      - timed: '30 2 * * *'
    properties:
      - authorization:
          'anonymous':
            - job-read
            - job-discover
      - build-blocker:
          blocking-jobs:
            - "^.*tempest-compute-host-check"
            - "^.*tempest-compute-host-check-advanced"
            - "^tempest-(?!.*rctest).*check.*"
          block-level: 'GLOBAL'
- job:
    name: tempest-image-check-run-all
    defaults: global
    node: tempest
    parameters:
      - choice:
          name: 'AVAILABILITY_ZONE'
          description: 'Availability zone. Use "Any zone" to allow the scheduler to choose.'
          choices:
            - Any zone
            - adelaide
            - ardc-syd-1
            - auckland
            - intersect-01
            - intersect-adelaide
            - melbourne-qh2
            - melbourne-qh2-uom
            - monash-01
            - monash-02
            - pawsey
            - qld
            - swinburne-01
            - tasmania
            - tasmania-02
    builders:
      - shell: |
          #!/bin/bash -eu
          export OS_USERNAME=$OS_USERNAME
          export OS_PASSWORD=$OS_PASSWORD
          export OS_AUTH_URL=https://identity.rc.nectar.org.au/v3
          export OS_PROJECT_DOMAIN_NAME=Default
          export OS_USER_DOMAIN_NAME=Default
          export OS_IDENTITY_API_VERSION=3
          export OS_PROJECT_NAME=NeCTAR-Images
          IMAGES=$(openstack image list --long --public | grep 28eadf5ad64b42a4929b2fb7df99275c | grep NeCTAR | awk '{print $2}')
          for IMAGE in $IMAGES; do
            echo "==> Triggering tempest-image-check job for $IMAGE..."
            curl -s -X POST https://jenkins.rc.nectar.org.au/job/tempest-image-check/build \
              --user $JENKINS_API_USER:$JENKINS_API_TOKEN \
              --data-urlencode json="{'parameter': [{'name':'IMAGE', 'value':'$IMAGE'}, {'name':'AVAILABILITY_ZONE', 'value':'$AVAILABILITY_ZONE'}]}"
          done
    wrappers:
      - credentials-binding:
          - username-password-separated:
              credential-id: 7a2e4b77-a292-47a1-b852-c0cfd9c1c383
              username: OS_USERNAME
              password: OS_PASSWORD
          - username-password-separated:
              credential-id: jenkins-api
              username: JENKINS_API_USER
              password: JENKINS_API_TOKEN
- job:
    name: tempest-image-check
    defaults: global
    node: tempest
    scm:
      - git:
          url: ssh://review.rc.nectar.org.au:29418/internal/nectar-testing.git
          credentials-id: cd8b8dd3-b897-4ecb-985d-180d5b6f8498
    parameters:
      - string:
          name: 'IMAGE'
          description: "Image ID to test."
      - choice:
          name: 'AVAILABILITY_ZONE'
          description: 'Availability zone. Use "Any zone" to allow the scheduler to choose.'
          choices:
            - Any zone
            - adelaide
            - ardc-syd-1
            - auckland
            - intersect-01
            - intersect-adelaide
            - melbourne-qh2
            - melbourne-qh2-uom
            - monash-01
            - monash-02
            - pawsey
            - qld
            - swinburne-01
            - tasmania
            - tasmania-02
    builders:
      - shell: |
          #!/bin/bash -eu
          export OS_USERNAME=$OS_USERNAME
          export OS_PASSWORD=$OS_PASSWORD
          export OS_AUTH_URL=https://identity.rc.nectar.org.au/v3
          export OS_PROJECT_DOMAIN_NAME=Default
          export OS_USER_DOMAIN_NAME=Default
          export OS_IDENTITY_API_VERSION=3
          export OS_PROJECT_NAME=NeCTAR-Images
          openstack image show --max-width=120 $IMAGE
          default_user=$(openstack image show -f value -c properties $IMAGE | sed 's/, /\n/g' | grep default_user | sed "s/'//g" | awk '{print $NF}')
          . /opt/tempest/bin/activate
          tmpdir=`mktemp -d --suffix=_tempest`
          cd $WORKSPACE/tempest
          [ "$AVAILABILITY_ZONE" != "Any zone" ] && SET_AZ="-s $AVAILABILITY_ZONE"
          ./setup_tempest.py $SET_AZ -e production --image $IMAGE --username $default_user -j check-image $tmpdir
          cd $tmpdir
          stestr run --serial --include-list $WORKSPACE/tempest/whitelists/check-image.yaml 2>&1 | grep --line-buffered -vE '   \w+Warning: |self._sock = None'
          RET=${PIPESTATUS[0]}
          rm -rf $tmpdir
          exit $RET
    wrappers:
      - credentials-binding:
          - username-password-separated:
              credential-id: 7a2e4b77-a292-47a1-b852-c0cfd9c1c383
              username: OS_USERNAME
              password: OS_PASSWORD
- job:
    name: tempest-nagios-toggle
    project-type: pipeline
    concurrent: false
    description: |
      Toggle (enable/disable) tempest nagios monitoring jobs.
      Use this during cloud issues to reduce system load.

      Security Note: This job requires Jenkins Script Security approval for:
      - Jenkins.instance access
      - Job.isDisabled(), Job.enable(), Job.disable() methods
      Approve these in: Manage Jenkins > In-process Script Approval
    parameters:
      - choice:
          name: 'ACTION'
          choices:
            - disable
            - enable
          description: "Action to perform on matching jobs"
      - choice:
          name: 'SCOPE'
          choices:
            - all-tests
            - all-compute-tests
            - all-network-tests
            - all-volume-tests
            - all-production-sites
            - all-testing-sites
            - site-adelaide
            - site-ardc-syd-1
            - site-auckland
            - site-intersect-01
            - site-intersect-adelaide
            - site-melbourne-qh2
            - site-melbourne-qh2-uom
            - site-monash-01
            - site-monash-02
            - site-pawsey
            - site-qld
            - site-swinburne-01
            - site-tasmania
            - site-tasmania-02
            - site-tasmania-s
            - site-ardctest-artm
            - site-qh2-test
            - site-monash-test
            - site-aucklandtest
          description: "Scope of jobs to toggle"
      - bool:
          name: 'DRY_RUN'
          default: true
          description: "If checked, only list jobs that would be affected without making changes"
    dsl: |
      // Get parameters
      def action = params.ACTION
      def scope = params.SCOPE
      def dryRun = params.DRY_RUN

      node('internal') {
          stage('Toggle Nagios Jobs') {
              // Site definitions (must match SCOPE parameter site-* choices)
              def PRODUCTION_SITES = ['adelaide', 'ardc-syd-1', 'auckland', 'intersect-01',
                                      'intersect-adelaide', 'melbourne-qh2', 'melbourne-qh2-uom',
                                      'monash-01', 'monash-02', 'pawsey', 'qld', 'swinburne-01',
                                      'tasmania', 'tasmania-02', 'tasmania-s']
              def TEST_SITES = ['ardctest-artm', 'qh2-test', 'monash-test', 'aucklandtest']

              // Audit logging
              def buildUser = currentBuild.getBuildCauses()[0]?.userId ?: 'SYSTEM'
              echo "=" * 50
              echo "[AUDIT] Tempest Nagios Job Toggle"
              echo "[AUDIT] User: ${buildUser}"
              echo "[AUDIT] Timestamp: ${new Date()}"
              echo "[AUDIT] Action: ${action}"
              echo "[AUDIT] Scope: ${scope}"
              echo "[AUDIT] DRY RUN: ${dryRun}"
              echo "=" * 50
              echo ""

              // Get Jenkins instance and find ALL tempest nagios jobs
              def jenkins = Jenkins.instance
              def allNagiosJobs = jenkins.getAllItems(hudson.model.Job.class).findAll { job ->
                  job.name.startsWith('tempest-nagios-')
              }

              // Filter jobs based on scope
              def matchingJobs = []
              switch (scope) {
                  case 'all-tests':
                      matchingJobs = allNagiosJobs
                      break

                  case 'all-compute-tests':
                      matchingJobs = allNagiosJobs.findAll { it.name.contains('-compute') }
                      break

                  case 'all-network-tests':
                      matchingJobs = allNagiosJobs.findAll { it.name.contains('-network') }
                      break

                  case 'all-volume-tests':
                      matchingJobs = allNagiosJobs.findAll {
                          it.name.contains('-volume') && !it.name.contains('volume_backup')
                      }
                      break

                  case 'all-production-sites':
                      matchingJobs = allNagiosJobs.findAll { job ->
                          PRODUCTION_SITES.any { site -> job.name =~ /tempest-nagios-(site|services)-${site}-/ }
                      }
                      break

                  case 'all-testing-sites':
                      matchingJobs = allNagiosJobs.findAll { job ->
                          TEST_SITES.any { site -> job.name =~ /tempest-nagios-(site|services)-${site}-/ }
                      }
                      break

                  default:
                      // Handle site-specific: site-adelaide -> adelaide
                      if (scope.startsWith('site-')) {
                          def site = scope.substring(5)

                          // Validate site is in known site list
                          def allSites = PRODUCTION_SITES + TEST_SITES
                          if (!allSites.contains(site)) {
                              error("Invalid site: ${site}. Must be one of: ${allSites.join(', ')}")
                          }

                          // Use regex for precise matching: tempest-nagios-site-{site}- or tempest-nagios-services-{site}-
                          matchingJobs = allNagiosJobs.findAll { job ->
                              job.name =~ /tempest-nagios-(site|services)-${site}-/
                          }
                      }
                      break
              }

              echo "Found ${matchingJobs.size()} matching job(s):"
              echo "=" * 50

              // Track statistics
              def alreadyInState = 0
              def toggledCount = 0

              // Process each job using for loop (CPS-friendly)
              for (int i = 0; i < matchingJobs.size(); i++) {
                  def job = matchingJobs[i]
                  def isDisabled = job.isDisabled()

                  // Check if action needed
                  if (action == 'enable' && !isDisabled) {
                      echo "   ${job.name} (already enabled)"
                      alreadyInState++
                  } else if (action == 'disable' && isDisabled) {
                      echo "   ${job.name} (already disabled)"
                      alreadyInState++
                  } else {
                      // Perform action
                      if (dryRun) {
                          echo "   ${job.name} (would ${action})"
                      } else {
                          try {
                              if (action == 'enable') {
                                  job.enable()
                              } else {
                                  job.disable()
                              }
                              echo "   ${job.name}... ${action}d "
                              toggledCount++
                          } catch (Exception e) {
                              echo "   ${job.name}... FAILED  (${e.message})"
                          }
                      }
                  }
              }

              // Print summary
              echo "=" * 50
              echo "Summary:"
              echo "  Total matching jobs: ${matchingJobs.size()}"
              echo "  Already in desired state: ${alreadyInState}"

              if (dryRun) {
                  def wouldToggle = matchingJobs.size() - alreadyInState
                  echo "  Would toggle: ${wouldToggle}"
                  echo ""
                  echo "  DRY RUN MODE - No changes made"
                  echo "Run with DRY_RUN=false to apply changes"
              } else {
                  echo "  Successfully toggled: ${toggledCount}"
                  if (toggledCount > 0) {
                      echo ""
                      echo "[AUDIT] ${toggledCount} jobs ${action}d by ${buildUser}"
                  }
              }
              echo "=" * 50
          }
      }
    properties:
      - authorization:
          'nobody':
            - job-read
            - job-discover
          'coreservices':
            - job-build
            - job-cancel
            - job-read
            - job-discover
      - build-discarder:
          num-to-keep: 50
      - build-blocker:
          blocking-jobs:
            - "tempest-nagios-toggle"
          block-level: 'GLOBAL'
